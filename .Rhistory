c_ranked <- sort(col_scores, decreasing = TRUE)
test <- data.frame(c_ranked[1:10])
colnames(test) <- "Quantity"
test$Column <- row.names(test)
if (onCols) {
test <- left_join(test, descriptions, by="Column")
return(gt::gt(test))
} else {
return(gt::gt(test))
}
}
# Which variables were most influential on where the companies were plotted for PC1 (x-axis?)
load_scores(PCA.1, 1, TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(glmnet)
library(ggplot2)
library(dplyr)
# Load data
cli <- read.csv('cost-of-living_v2.csv')
dim(cli)
varData <- setNames(stack(sapply(cli, class))[2:1], c('variable', 'class'))
descriptions <- read.csv('Descriptions.csv')
descriptions <- descriptions[, c('Column', 'Description')]
gt::gt(descriptions)
knitr::opts_chunk$set(echo = TRUE)
library(glmnet)
library(ggplot2)
library(dplyr)
# Load data
cli <- read.csv('cost-of-living_v2.csv')
dim(cli)
varData <- setNames(stack(sapply(cli, class))[2:1], c('variable', 'class'))
descriptions <- read.csv('Descriptions.csv')
descriptions <- descriptions[, c('Column', 'Description')]
gt::gt(descriptions)
# Function for plotting on GG plot. Takes in data and PCs(int) to plot
pca.gg <- function(d, n1, n2) {
# Variation
p.var <- d$sdev^2
p.var.per <- round(p.var / sum(p.var)*100, 1)
ggD <- data.frame(Sample=rownames(d$x), X=d$x[,n1], Y=d$x[,n2])
ggplot(data=ggD, aes(x=X, y=Y, label=Sample)) +
geom_text() +
xlab(paste("PC", n1, p.var.per[n1], "%", sep = " ")) +
ylab(paste("PC", n2, p.var.per[n2], "%", sep=" ")) +
ggtitle("PCA Graph")
}
# Loading scores
load_scores <- function(d, n, onCols) {
loading_scores <- d$rotation[, n]
col_scores <- abs(loading_scores)
c_ranked <- sort(col_scores, decreasing = TRUE)
test <- data.frame(c_ranked[1:10])
colnames(test) <- "Loading Score"
test$Column <- row.names(test)
if (onCols) {
test <- left_join(test, descriptions, by="Column")
return(gt::gt(test))
} else {
return(gt::gt(test))
}
}
# Scree plot
s_plot <- function(d){
pca.var <- d$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100, 1)
barplot(pca.var.per, main="Screeplot", xlab="Principal Component",
ylab="% variation")
}
PCA.data <- cli[complete.cases(cli), ]
row.names(PCA.data) <- paste(PCA.data$city, PCA.data$country, sep = ", ")
PCA.data <- subset(PCA.data, select=-c(city, country))
PCA.1 <- prcomp(PCA.data, scale=TRUE, tol = 0.1)
s_plot(PCA.1)
pca.gg(PCA.1, 1, 2)
# Which variables were most influential on where the companies were plotted for PC1 (x-axis?)
load_scores(PCA.1, 1, TRUE)
# Which variables were most influential on where the companies were plotted for PC2 (y-axis?)
load_scores(PCA.1, 2, TRUE)
load_scores(PCA.1, 3, TRUE)
PCA.data2 <- t(data.matrix(PCA.data))
PCA.data2 <- t(apply(PCA.data2, 1, function(x)(x-min(x))/(max(x)-min(x))))
PCA.2 <- prcomp(PCA.data2)
s_plot(PCA.2)
# Graph
pca.gg(PCA.2, 1, 2)
# What companies were most influential on where the variables were plotted for PC1?
load_scores(PCA.2, 1, FALSE)
# PC2?
load_scores(PCA.2, 2, FALSE)
PCA.data <- cli[complete.cases(cli), ]
row.names(PCA.data) <- paste(PCA.data$city, PCA.data$country, sep = ", ")
PCA.data <- subset(PCA.data, select=-c(city, country))
PCA.1 <- prcomp(PCA.data, scale=TRUE, tol = 0.1)
s_plot(PCA.1)
pca.gg(PCA.1, 1, 2)
# Which variables were most influential on where the companies were plotted for PC1 (x-axis?)
load_scores(PCA.1, 1, TRUE)
# Which variables were most influential on where the companies were plotted for PC2 (y-axis?)
load_scores(PCA.1, 2, TRUE)
load_scores(PCA.1, 3, TRUE)
PCA.data2 <- t(data.matrix(PCA.data))
PCA.data2 <- t(apply(PCA.data2, 1, function(x)(x-min(x))/(max(x)-min(x))))
PCA.2 <- prcomp(PCA.data2)
s_plot(PCA.2)
# Graph
pca.gg(PCA.2, 1, 2)
# What companies were most influential on where the variables were plotted for PC1?
load_scores(PCA.2, 1, FALSE)
# PC2?
load_scores(PCA.2, 2, FALSE)
library(yaml)
install.packages(rmarkdown)
install.packages('rmarkdown')
install.packages("rmarkdown")
install.packages("rmarkdown")
install.packages("rmarkdown")
install.packages('yaml')
install.packages('knitr')
install.packages("knitr")
install.packages("knitr")
knitr::opts_chunk$set(echo = TRUE)
library(glmnet)
library(ggplot2)
library(dplyr)
setwd("~/Documents/PRL/Projects/Winter Break Project/GlobalCLI")
# Load data
cli <- read.csv('cost-of-living_v2.csv')
dim(cli)
varData <- setNames(stack(sapply(cli, class))[2:1], c('variable', 'class'))
descriptions <- read.csv('Descriptions.csv')
descriptions <- descriptions[, c('Column', 'Description')]
gt::gt(descriptions)
# Function for plotting on GG plot. Takes in data and PCs(int) to plot
pca.gg <- function(d, n1, n2) {
# Variation
p.var <- d$sdev^2
p.var.per <- round(p.var / sum(p.var)*100, 1)
ggD <- data.frame(Sample=rownames(d$x), X=d$x[,n1], Y=d$x[,n2])
ggplot(data=ggD, aes(x=X, y=Y, label=Sample)) +
geom_text() +
xlab(paste("PC", n1, p.var.per[n1], "%", sep = " ")) +
ylab(paste("PC", n2, p.var.per[n2], "%", sep=" ")) +
ggtitle("PCA Graph")
}
# Loading scores
load_scores <- function(d, n, onCols) {
loading_scores <- d$rotation[, n]
col_scores <- abs(loading_scores)
c_ranked <- sort(col_scores, decreasing = TRUE)
test <- data.frame(c_ranked[1:10])
colnames(test) <- "Loading Score"
test$Column <- row.names(test)
if (onCols) {
test <- left_join(test, descriptions, by="Column")
return(gt::gt(test))
} else {
return(gt::gt(test))
}
}
# Scree plot
s_plot <- function(d){
pca.var <- d$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100, 1)
barplot(pca.var.per, main="Screeplot", xlab="Principal Component",
ylab="% variation")
}
PCA.data <- cli[complete.cases(cli), ]
row.names(PCA.data) <- paste(PCA.data$city, PCA.data$country, sep = ", ")
PCA.data <- subset(PCA.data, select=-c(city, country))
PCA.1 <- prcomp(PCA.data, scale=TRUE, tol = 0.1)
s_plot(PCA.1)
pca.gg(PCA.1, 1, 2)
# Which variables were most influential on where the companies were plotted for PC1 (x-axis?)
load_scores(PCA.1, 1, TRUE)
# Which variables were most influential on where the companies were plotted for PC2 (y-axis?)
load_scores(PCA.1, 2, TRUE)
load_scores(PCA.1, 3, TRUE)
PCA.data2 <- t(data.matrix(PCA.data))
PCA.data2 <- t(apply(PCA.data2, 1, function(x)(x-min(x))/(max(x)-min(x))))
PCA.2 <- prcomp(PCA.data2)
s_plot(PCA.2)
# Graph
pca.gg(PCA.2, 1, 2)
# What companies were most influential on where the variables were plotted for PC1?
load_scores(PCA.2, 1, FALSE)
# PC2?
load_scores(PCA.2, 2, FALSE)
y <- cli$x54
x <- cli %>% select(-c(x54))
cv_model <- cv.glmnet(x, y, alpha = 1)
cross_val_model <- cv.glmnet(x, y, alpha = 1)
x <- cli %>% select(-c(x54))
knitr::opts_chunk$set(echo = TRUE)
library(glmnet)
library(ggplot2)
library(dplyr)
# Load data
cli <- read.csv('cost-of-living_v2.csv')
# Remove any columns with NA values
cli <- cli[complete.cases(cli), ]
dim(cli)
varData <- setNames(stack(sapply(cli, class))[2:1], c('variable', 'class'))
descriptions <- read.csv('Descriptions.csv')
descriptions <- descriptions[, c('Column', 'Description')]
gt::gt(descriptions)
# Function for plotting on GG plot. Takes in data and PCs(int) to plot
pca.gg <- function(d, n1, n2) {
# Variation
p.var <- d$sdev^2
p.var.per <- round(p.var / sum(p.var)*100, 1)
ggD <- data.frame(Sample=rownames(d$x), X=d$x[,n1], Y=d$x[,n2])
ggplot(data=ggD, aes(x=X, y=Y, label=Sample)) +
geom_text() +
xlab(paste("PC", n1, p.var.per[n1], "%", sep = " ")) +
ylab(paste("PC", n2, p.var.per[n2], "%", sep=" ")) +
ggtitle("PCA Graph")
}
# Loading scores
load_scores <- function(d, n, onCols) {
loading_scores <- d$rotation[, n]
col_scores <- abs(loading_scores)
c_ranked <- sort(col_scores, decreasing = TRUE)
test <- data.frame(c_ranked[1:10])
colnames(test) <- "Loading Score"
test$Column <- row.names(test)
if (onCols) {
test <- left_join(test, descriptions, by="Column")
return(gt::gt(test))
} else {
return(gt::gt(test))
}
}
# Scree plot
s_plot <- function(d){
pca.var <- d$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100, 1)
barplot(pca.var.per, main="Screeplot", xlab="Principal Component",
ylab="% variation")
}
PCA.data <- cli
row.names(PCA.data) <- paste(PCA.data$city, PCA.data$country, sep = ", ")
PCA.data <- subset(PCA.data, select=-c(city, country))
PCA.1 <- prcomp(PCA.data, scale=TRUE, tol = 0.1)
s_plot(PCA.1)
pca.gg(PCA.1, 1, 2)
# Which variables were most influential on where the companies were plotted for PC1 (x-axis?)
load_scores(PCA.1, 1, TRUE)
# Which variables were most influential on where the companies were plotted for PC2 (y-axis?)
load_scores(PCA.1, 2, TRUE)
load_scores(PCA.1, 3, TRUE)
PCA.data2 <- t(data.matrix(PCA.data))
PCA.data2 <- t(apply(PCA.data2, 1, function(x)(x-min(x))/(max(x)-min(x))))
PCA.2 <- prcomp(PCA.data2)
s_plot(PCA.2)
# Graph
pca.gg(PCA.2, 1, 2)
# What companies were most influential on where the variables were plotted for PC1?
load_scores(PCA.2, 1, FALSE)
# PC2?
load_scores(PCA.2, 2, FALSE)
y <- cli$x54
x <- cli %>% select(-c(x54))
cross_val_model <- cv.glmnet(x, y, alpha = 1)
y <- cli$x54
x <- data.matrix(cli %>% select(-c(x54)))
cross_val_model <- cv.glmnet(x, y, alpha = 1)
best_lamda
# Find lambda value
cross_val_model <- cv.glmnet(x, y, alpha = 1)
# Find lambda value
cross_val_model <- cv.glmnet(x, y, alpha = 1)
best_lamda <- cross_val_model$lambda.min
best_lamda
# Produce plot of test MSE by lambda value
plot(cross_val_model)
best_model <- glmnet(x, y, alpha = 1, lamda = best_lamda)
# Find SST and SSE
sst <- sum((y- mean(y))^2)
#find R-Squared
rsq <- 1 - sse/sst
# Find SST and SSE
sst <- sum((y- mean(y))^2)
sse <- sum((y_pred - Y)^2)
y <- cli$x54
x <- data.matrix(cli %>% select(-c(x54)))
# Find lambda value
cross_val_model <- cv.glmnet(x, y, alpha = 1)
best_lamda <- cross_val_model$lambda.min
best_lamda
# Produce plot of test MSE by lambda value
plot(cross_val_model)
best_model <- glmnet(x, y, alpha = 1, lamda = best_lamda)
y_pred = predict(best_model, s = best_lamda, newx = x)
# Find SST and SSE
sst <- sum((y- mean(y))^2)
sse <- sum((y_pred - Y)^2)
y <- cli$x54
x <- data.matrix(cli %>% select(-c(x54)))
# Find lambda value
cross_val_model <- cv.glmnet(x, y, alpha = 1)
best_lamda <- cross_val_model$lambda.min
best_lamda
# Produce plot of test MSE by lambda value
plot(cross_val_model)
best_model <- glmnet(x, y, alpha = 1, lamda = best_lamda)
y_pred = predict(best_model, s = best_lamda, newx = x)
# Find SST and SSE
sst <- sum((y- mean(y))^2)
sse <- sum((y_pred - Y)^2)
y <- cli$x54
x <- data.matrix(cli %>% select(-c(x54)))
# Find lambda value
cross_val_model <- cv.glmnet(x, y, alpha = 1)
best_lamda <- cross_val_model$lambda.min
best_lamda
# Produce plot of test MSE by lambda value
plot(cross_val_model)
best_model <- glmnet(x, y, alpha = 1, lamda = best_lamda)
y_pred = predict(best_model, s = best_lamda, newx = x)
# Find SST and SSE
sst <- sum((y- mean(y))^2)
sse <- sum((y_pred - y)^2)
#find R-Squared
rsq <- 1 - sse/sst
rsq
# Best model explains {rsq * 100}% of the variation in the response values of the training data
# Which metrics are most important?
# Extracts non-zero coefficients
print(coef(best_model))
# Which metrics are most important?
# Extracts non-zero coefficients
coefficients <- coef(best_model)
View(coefficients)
# Which metrics are most important?
# Extracts non-zero coefficients
coeffs <- coef(best_model)
# Which metrics are most important?
# Extracts non-zero coefficients
coeffs <- coef(best_model)
coeffs
class(coeffs)
# Which metrics are most important?
# Extracts non-zero coefficients
coeffs <- coef(best_model, s = "lambda.min")
# Which metrics are most important?
# Extracts non-zero coefficients
c.fficients <- coef(best_model, s = "lambda.min")
best_model$lambda
y <- cli$x54
x <- data.matrix(cli %>% select(-c(x54, city, country, data_quality)))
y <- cli$x54
x <- data.matrix(cli %>% select(-c(x54, city, country, data_quality)))
# Find lambda value
cross_val_model <- cv.glmnet(x, y, alpha = 1)
best_lamda <- cross_val_model$lambda.min
best_lamda
# Produce plot of test MSE by lambda value
plot(cross_val_model)
best_model <- glmnet(x, y, alpha = 1, lamda = best_lamda)
y_pred = predict(best_model, s = best_lamda, newx = x)
# Find SST and SSE
sst <- sum((y- mean(y))^2)
sse <- sum((y_pred - y)^2)
#find R-Squared
rsq <- 1 - sse/sst
rsq
# Best model explains {rsq * 100}% of the variation in the response values of the training data
# Which metrics are most important?
# Extracts non-zero coefficients
c.fficients <- coef(best_model)
c.fficients
c.fficients$s0
c.fficients
x <- cli %>% select(-c(x54, city, country, data_quality))
y <- cli$x54
x <- cli %>% select(-c(x54, city, country, data_quality))
# Find lambda value
cross_val_model <- cv.glmnet(x, y, alpha = 1)
y <- cli$x54
x <- cli %>% select(-c(x54, city, country, data_quality))
x <- data.matrix(x)
# Find lambda value
cross_val_model <- cv.glmnet(x, y, alpha = 1)
best_lamda <- cross_val_model$lambda.min
best_lamda
# Produce plot of test MSE by lambda value
plot(cross_val_model)
best_model <- glmnet(x, y, alpha = 1, lamda = best_lamda)
y_pred = predict(best_model, s = best_lamda, newx = x)
# Find SST and SSE
sst <- sum((y- mean(y))^2)
sse <- sum((y_pred - y)^2)
#find R-Squared
rsq <- 1 - sse/sst
rsq
# Which metrics are most important?
# Extracts non-zero coefficients
c.fficients <- coef(best_model)
c.fficients
best_model <- glmnet(x, y, alpha = 1, lamda = best_lamda)
coef(best_model)
x <- data.matrix(x)
View(best_model)
View(x)
# Which metrics are most important?
# Extracts non-zero coefficients
c.fficients <- coef(best_model, s = 188.408848)
c.fficients
# Which metrics are most important?
# Extracts non-zero coefficients
c.fficients <- coef(best_model, s = 0)
c.fficients
# Which metrics are most important?
# Extracts non-zero coefficients
c.fficients <- coef(best_model, s = 1)
c.fficients
# Which metrics are most important?
# Extracts non-zero coefficients
c.fficients <- coef(best_model, s = best_lamda)
c.fficients
row.names(c.fficients)
c.fficients$Column <- row.names(c.ffficients)
c.fficients$Column <- row.names(c.fficients)
left_join(c.fficients, descriptions, by="Column")
c.fficients <- data.frame(c.fficients)
c.fficients <- data.matrix(c.fficients)
c.fficients
c.fficients <- data.frame(c.fficients)
c.fficients
c.fficients
View(c.fficients)
c.fficients$Column <- row.names(c.fficients)
left_join(c.fficients, descriptions, by="Column")
c.fficients <- left_join(c.fficients, descriptions, by="Column")
c.fficients
View(c.fficients)
gt::gt(c.fficients)
# Which metrics are most important?
# Extracts non-zero coefficients
c.fficients <- coef(best_model, s = best_lamda)
c.fficients
class(c.fficients$s1)
c.fficients <- coef(best_model, s = best_lamda)
c.fficients
c.fficients <- data.matrix(c.fficients)
c.fficients <- data.frame(c.fficients)
c.fficients
c.fficients$Column <- row.names(c.fficients)
c.fficients <- left_join(c.fficients, descriptions, by="Column")
class(c.fficients$s1)
c.fficients$s1 == 0
c.fficients <- filter(c.fficients, s1 > 0)
gt::gt(c.fficients)
y <- cli$x54
x <- cli %>% select(-c(x54, city, country, data_quality))
x <- data.matrix(x)
# Find lambda value
cross_val_model <- cv.glmnet(x, y, alpha = 1)
best_lamda <- cross_val_model$lambda.min
best_lamda
# Produce plot of test MSE by lambda value
plot(cross_val_model)
best_model <- glmnet(x, y, alpha = 1, lamda = best_lamda)
coef(best_model)
y_pred = predict(best_model, s = best_lamda, newx = x)
# Find SST and SSE
sst <- sum((y- mean(y))^2)
sse <- sum((y_pred - y)^2)
#find R-Squared
rsq <- 1 - sse/sst
rsq
# Best model explains {rsq * 100}% of the variation in the response values of the training data
# Which metrics are most important?
# Extracts non-zero coefficients
predictors <- coef(best_model, s = best_lamda)
predictors
predictors <- data.matrix(predictors)
predictors <- data.frame(predictors)
predictors
predictors$Column <- row.names(predictors)
predictors <- left_join(predictors, descriptions, by="Column")
predictors <- filter(predictors, s1 > 0)
gt::gt(predictors)
y <- cli$x54
x <- cli %>% select(-c(x54, city, country, data_quality))
x <- data.matrix(x)
# Find lambda value
cross_val_model <- cv.glmnet(x, y, alpha = 1)
best_lamda <- cross_val_model$lambda.min
best_lamda
# Produce plot of test MSE by lambda value
plot(cross_val_model)
best_model <- glmnet(x, y, alpha = 1, lamda = best_lamda)
coef(best_model)
y_pred = predict(best_model, s = best_lamda, newx = x)
# Find SST and SSE
sst <- sum((y- mean(y))^2)
sse <- sum((y_pred - y)^2)
#find R-Squared
rsq <- 1 - sse/sst
rsq
# Best model explains {rsq * 100}% of the variation in the response values of the training data
# Which metrics are most important?
# Extracts non-zero coefficients
predictors <- coef(best_model, s = best_lamda)
predictors <- data.matrix(predictors)
predictors <- data.frame(predictors)
predictors$Column <- row.names(predictors)
predictors <- left_join(predictors, descriptions, by="Column")
predictors <- filter(predictors, s1 > 0)
gt::gt(predictors)
